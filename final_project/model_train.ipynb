{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt, exp, ceil\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     LN(總價)  中正區  大安區  松山區  南港區  內湖區  信義區  中山區  士林區  文山區  ...  公園_路距(公里)  \\\n",
      "0  7.681560    0    0    0    0    1    0    0    0    0  ...   0.031904   \n",
      "1  7.299797    0    0    0    0    0    0    0    0    0  ...   0.047884   \n",
      "2  7.244228    0    1    0    0    0    0    0    0    0  ...   0.077494   \n",
      "3  7.494430    0    0    0    0    0    0    1    0    0  ...   0.052085   \n",
      "4  7.937375    0    0    0    0    0    0    0    1    0  ...   0.087862   \n",
      "\n",
      "   公車站_路距(公里)  國小_路距(公里)  國中_路距(公里)  高中職_路距(公里)  採光  管理  邊間  裝潢  景觀  \n",
      "0    0.177010   0.371121   0.551265    0.441955   0   0   1   1   0  \n",
      "1    0.001689   0.142749   0.336884    0.558161   1   0   0   0   0  \n",
      "2    0.097310   0.105114   0.126316    0.105385   0   1   0   1   0  \n",
      "3    0.035048   0.111924   0.104736    0.137254   1   0   0   0   0  \n",
      "4    0.083993   0.061999   0.304394    0.165038   0   0   0   0   0  \n",
      "\n",
      "[5 rows x 36 columns] Index(['LN(總價)', '中正區', '大安區', '松山區', '南港區', '內湖區', '信義區', '中山區', '士林區', '文山區',\n",
      "       '北投區', '大同區', '萬華區', '住宅區', '商業區', '住商混合區', '公寓', '華廈', '住宅大樓',\n",
      "       'LN(建物面積)', '樓層', 'LN(屋齡)', '台鐵_直距(公里)', '百貨_直距(公里)', '大專_直距(公里)',\n",
      "       '捷運_路距(公里)', '公園_路距(公里)', '公車站_路距(公里)', '國小_路距(公里)', '國中_路距(公里)',\n",
      "       '高中職_路距(公里)', '採光', '管理', '邊間', '裝潢', '景觀'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# https://jovian.ai/aakashns/02-linear-regression\n",
    "\n",
    "# load house price related data\n",
    "# https://scikit-learn.org/stable/modules/preprocessing.html\n",
    "\n",
    "\n",
    "data=pd.read_excel('16實證資料.xlsx', usecols='A:Y, AA:AG, AI:AJ, AN:AO')\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "data['台鐵_直距(公里)'] = min_max_scaler.fit_transform(np.array(data['台鐵_直距(公里)']).reshape(-1, 1))\n",
    "data['百貨_直距(公里)'] = min_max_scaler.fit_transform(np.array(data['百貨_直距(公里)']).reshape(-1, 1))\n",
    "data['大專_直距(公里)'] = min_max_scaler.fit_transform(np.array(data['大專_直距(公里)']).reshape(-1, 1))\n",
    "data['捷運_路距(公里)'] = min_max_scaler.fit_transform(np.array(data['捷運_路距(公里)']).reshape(-1, 1))\n",
    "data['公園_路距(公里)'] = min_max_scaler.fit_transform(np.array(data['公園_路距(公里)']).reshape(-1, 1))\n",
    "data['公車站_路距(公里)'] = min_max_scaler.fit_transform(np.array(data['公車站_路距(公里)']).reshape(-1, 1))\n",
    "data['國小_路距(公里)'] = min_max_scaler.fit_transform(np.array(data['國小_路距(公里)']).reshape(-1, 1))\n",
    "data['國中_路距(公里)'] = min_max_scaler.fit_transform(np.array(data['國中_路距(公里)']).reshape(-1, 1))\n",
    "data['高中職_路距(公里)'] = min_max_scaler.fit_transform(np.array(data['高中職_路距(公里)']).reshape(-1, 1))\n",
    "\n",
    "\n",
    "# data clean and transform \n",
    "for d in data['樓層']:\n",
    "    if type(d)!=int:\n",
    "        data.drop(data.loc[data['樓層']==d].index, inplace=True)\n",
    "        \n",
    "\n",
    "print(data.head(), data.columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X=torch.from_numpy(np.array(data.drop(columns='LN(總價)'), dtype='float32'))\n",
    "y=torch.from_numpy(np.array(data['LN(總價)'], dtype='float32'))\n",
    "\n",
    "# 80%, 20%\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    random_state=12\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter containing:\n",
      "tensor([[-0.1260,  0.1328,  0.1010,  0.0568, -0.0545, -0.1444,  0.0280,  0.0829,\n",
      "          0.1054,  0.0941,  0.1536, -0.0038,  0.0698,  0.0599,  0.1208, -0.1020,\n",
      "         -0.0247,  0.0375, -0.1687, -0.0934,  0.1346, -0.0377, -0.0670,  0.0455,\n",
      "         -0.0520, -0.1260,  0.0645, -0.1435,  0.0608, -0.0736,  0.0930,  0.1436,\n",
      "          0.1211, -0.0394, -0.1511]], requires_grad=True)\n",
      "Parameter containing:\n",
      "tensor([-0.0292], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "# Define dataset\n",
    "train_ds = TensorDataset(X_train, y_train)\n",
    "test_ds = TensorDataset(X_test, y_test)\n",
    "\n",
    "# Define data loader\n",
    "batch_size = 5\n",
    "train_dl = DataLoader(train_ds, batch_size, shuffle=True)\n",
    "test_dl = DataLoader(test_ds, batch_size, shuffle=True)\n",
    "\n",
    "# Define model\n",
    "input_size = list(X_train.shape)[1]\n",
    "model = nn.Linear(input_size, 1) #1234\n",
    "print(model.weight)\n",
    "print(model.bias)\n",
    "\n",
    "\n",
    "# # Function to save the model \n",
    "def saveModel(): \n",
    "    model_scripted = torch.jit.script(model) # Export to TorchScript\n",
    "    model_scripted.save('model_final.pt') # Save\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(72.1154, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "# Generate predictions\n",
    "preds = model(X_train)\n",
    "preds\n",
    "\n",
    "\n",
    "# Define loss function\n",
    "loss_fn = F.mse_loss\n",
    "\n",
    "loss = loss_fn(model(X_train).ravel(), y_train)\n",
    "print(loss)\n",
    "\n",
    "# Define optimizer\n",
    "opt = torch.optim.Adam(model.parameters(), lr=1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/1000], Training Loss: 59.3074%\n",
      "Epoch [20/1000], Training Loss: 47.3226%\n",
      "Epoch [30/1000], Training Loss: 36.7603%\n",
      "Epoch [40/1000], Training Loss: 27.6405%\n",
      "Epoch [50/1000], Training Loss: 19.9284%\n",
      "Epoch [60/1000], Training Loss: 13.6432%\n",
      "Epoch [70/1000], Training Loss: 8.7672%\n",
      "Epoch [80/1000], Training Loss: 5.2938%\n",
      "Epoch [90/1000], Training Loss: 3.1828%\n",
      "Epoch [100/1000], Training Loss: 2.1896%\n",
      "Epoch [110/1000], Training Loss: 1.8023%\n",
      "Epoch [120/1000], Training Loss: 1.6217%\n",
      "Epoch [130/1000], Training Loss: 1.4976%\n",
      "Epoch [140/1000], Training Loss: 1.3950%\n",
      "Epoch [150/1000], Training Loss: 1.3049%\n",
      "Epoch [160/1000], Training Loss: 1.2220%\n",
      "Epoch [170/1000], Training Loss: 1.1479%\n",
      "Epoch [180/1000], Training Loss: 1.0814%\n",
      "Epoch [190/1000], Training Loss: 1.0218%\n",
      "Epoch [200/1000], Training Loss: 0.9657%\n",
      "Epoch [210/1000], Training Loss: 0.9124%\n",
      "Epoch [220/1000], Training Loss: 0.8654%\n",
      "Epoch [230/1000], Training Loss: 0.8207%\n",
      "Epoch [240/1000], Training Loss: 0.7799%\n",
      "Epoch [250/1000], Training Loss: 0.7399%\n",
      "Epoch [260/1000], Training Loss: 0.7036%\n",
      "Epoch [270/1000], Training Loss: 0.6688%\n",
      "Epoch [280/1000], Training Loss: 0.6372%\n",
      "Epoch [290/1000], Training Loss: 0.6053%\n",
      "Epoch [300/1000], Training Loss: 0.5760%\n",
      "Epoch [310/1000], Training Loss: 0.5485%\n",
      "Epoch [320/1000], Training Loss: 0.5223%\n",
      "Epoch [330/1000], Training Loss: 0.4973%\n",
      "Epoch [340/1000], Training Loss: 0.4742%\n",
      "Epoch [350/1000], Training Loss: 0.4516%\n",
      "Epoch [360/1000], Training Loss: 0.4306%\n",
      "Epoch [370/1000], Training Loss: 0.4103%\n",
      "Epoch [380/1000], Training Loss: 0.3913%\n",
      "Epoch [390/1000], Training Loss: 0.3734%\n",
      "Epoch [400/1000], Training Loss: 0.3562%\n",
      "Epoch [410/1000], Training Loss: 0.3402%\n",
      "Epoch [420/1000], Training Loss: 0.3253%\n",
      "Epoch [430/1000], Training Loss: 0.3105%\n",
      "Epoch [440/1000], Training Loss: 0.2967%\n",
      "Epoch [450/1000], Training Loss: 0.2841%\n",
      "Epoch [460/1000], Training Loss: 0.2715%\n",
      "Epoch [470/1000], Training Loss: 0.2599%\n",
      "Epoch [480/1000], Training Loss: 0.2489%\n",
      "Epoch [490/1000], Training Loss: 0.2387%\n",
      "Epoch [500/1000], Training Loss: 0.2287%\n",
      "Epoch [510/1000], Training Loss: 0.2199%\n",
      "Epoch [520/1000], Training Loss: 0.2107%\n",
      "Epoch [530/1000], Training Loss: 0.2024%\n",
      "Epoch [540/1000], Training Loss: 0.1944%\n",
      "Epoch [550/1000], Training Loss: 0.1871%\n",
      "Epoch [560/1000], Training Loss: 0.1802%\n",
      "Epoch [570/1000], Training Loss: 0.1737%\n",
      "Epoch [580/1000], Training Loss: 0.1675%\n",
      "Epoch [590/1000], Training Loss: 0.1616%\n",
      "Epoch [600/1000], Training Loss: 0.1565%\n",
      "Epoch [610/1000], Training Loss: 0.1510%\n",
      "Epoch [620/1000], Training Loss: 0.1464%\n",
      "Epoch [630/1000], Training Loss: 0.1418%\n",
      "Epoch [640/1000], Training Loss: 0.1376%\n",
      "Epoch [650/1000], Training Loss: 0.1335%\n",
      "Epoch [660/1000], Training Loss: 0.1299%\n",
      "Epoch [670/1000], Training Loss: 0.1264%\n",
      "Epoch [680/1000], Training Loss: 0.1229%\n",
      "Epoch [690/1000], Training Loss: 0.1200%\n",
      "Epoch [700/1000], Training Loss: 0.1171%\n",
      "Epoch [710/1000], Training Loss: 0.1142%\n",
      "Epoch [720/1000], Training Loss: 0.1115%\n",
      "Epoch [730/1000], Training Loss: 0.1092%\n",
      "Epoch [740/1000], Training Loss: 0.1073%\n",
      "Epoch [750/1000], Training Loss: 0.1046%\n",
      "Epoch [760/1000], Training Loss: 0.1026%\n",
      "Epoch [770/1000], Training Loss: 0.1006%\n",
      "Epoch [780/1000], Training Loss: 0.0987%\n",
      "Epoch [790/1000], Training Loss: 0.0970%\n",
      "Epoch [800/1000], Training Loss: 0.0954%\n",
      "Epoch [810/1000], Training Loss: 0.0937%\n",
      "Epoch [820/1000], Training Loss: 0.0923%\n",
      "Epoch [830/1000], Training Loss: 0.0909%\n",
      "Epoch [840/1000], Training Loss: 0.0895%\n",
      "Epoch [850/1000], Training Loss: 0.0882%\n",
      "Epoch [860/1000], Training Loss: 0.0870%\n",
      "Epoch [870/1000], Training Loss: 0.0858%\n",
      "Epoch [880/1000], Training Loss: 0.0847%\n",
      "Epoch [890/1000], Training Loss: 0.0837%\n",
      "Epoch [900/1000], Training Loss: 0.0826%\n",
      "Epoch [910/1000], Training Loss: 0.0816%\n",
      "Epoch [920/1000], Training Loss: 0.0808%\n",
      "Epoch [930/1000], Training Loss: 0.0799%\n",
      "Epoch [940/1000], Training Loss: 0.0790%\n",
      "Epoch [950/1000], Training Loss: 0.0782%\n",
      "Epoch [960/1000], Training Loss: 0.0774%\n",
      "Epoch [970/1000], Training Loss: 0.0766%\n",
      "Epoch [980/1000], Training Loss: 0.0759%\n",
      "Epoch [990/1000], Training Loss: 0.0752%\n",
      "Epoch [1000/1000], Training Loss: 0.0746%\n"
     ]
    }
   ],
   "source": [
    "# Utility function to train the model\n",
    "def fit(num_epochs, model, loss_fn, opt, train_dl):\n",
    "    \n",
    "    # Repeat for given number of epochs\n",
    "    for epoch in range(num_epochs):\n",
    "        running_train_loss = 0.0\n",
    "        \n",
    "        # Train with batches of data\n",
    "        for xb,yb in train_dl:\n",
    "            \n",
    "            # 1. Generate predictions\n",
    "            pred = model(xb).ravel()\n",
    "            #print(pred)\n",
    "            #print(yb)\n",
    "            \n",
    "            # 2. Calculate loss\n",
    "            loss = loss_fn(pred, yb)\n",
    "            \n",
    "            # 3. Compute gradients\n",
    "            loss.backward()\n",
    "            \n",
    "            # 4. Update parameters using gradients\n",
    "            opt.step()\n",
    "            \n",
    "            # 5. Reset the gradients to zero\n",
    "            opt.zero_grad()\n",
    "            \n",
    "            # Calculate training loss value \n",
    "            running_train_loss += loss.item()\n",
    "        \n",
    "        train_loss_value = running_train_loss/len(train_dl) \n",
    "        \n",
    "        # Print the progress\n",
    "        if (epoch+1) % 10 == 0:\n",
    "            print('Epoch [{}/{}], Training Loss: {:.4f}%'.format(epoch+1, num_epochs, train_loss_value))\n",
    "    \n",
    "\n",
    "fit(1000, model, loss_fn, opt, train_dl)\n",
    "saveModel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Actual Observation  Predicted Price\n",
      "0  tensor(4599.9980)      4376.166094\n",
      "1  tensor(8800.0010)      7038.349334\n",
      "2  tensor(1038.0001)       927.093236\n",
      "3  tensor(1100.0001)       722.768081\n",
      "4  tensor(9687.9990)      9105.052679\n",
      "Price\n",
      "mean_absolute_error: 716.9258672389066\n",
      "mean_squared_error: 2212179.665504863\n",
      "rmse: 1487.3397949039295\n",
      "r2 score: 0.8452700366531083\n"
     ]
    }
   ],
   "source": [
    "# test data\n",
    "# https://medium.com/analytics-vidhya/linear-regression-with-pytorch-147fed55f138\n",
    "\n",
    "# model results\n",
    "# 衡量線性迴歸的MSE 、 RMSE、 MAE、r2\n",
    "\n",
    "\n",
    "model = torch.jit.load('model_final.pt')\n",
    "model.eval()\n",
    "\n",
    "y_pred_test = model(X_test)\n",
    "\n",
    "y_pred_test = [y_pred_test[x].item() for x in range(len(y_pred_test))]\n",
    "# Comparing Actual and predicted values\n",
    "df = {}\n",
    "df['Actual Observation'] = y_test\n",
    "df['Predicted Price'] = y_pred_test\n",
    "\n",
    "\n",
    "for i in range(len(y_test)):\n",
    "    df['Actual Observation'][i] = exp(df['Actual Observation'][i])\n",
    "    df['Predicted Price'][i] = exp(df['Predicted Price'][i])\n",
    "df = pd.DataFrame(df)\n",
    "print(df.head())\n",
    "\n",
    "\n",
    "print('Price')\n",
    "print(\"mean_absolute_error:\",mean_absolute_error(df['Actual Observation'],df['Predicted Price']))\n",
    "print(\"mean_squared_error:\",mean_squared_error(df['Actual Observation'],df['Predicted Price']))\n",
    "print(\"rmse:\",sqrt(mean_squared_error(df['Actual Observation'],df['Predicted Price'])))\n",
    "print(\"r2 score:\",r2_score(df['Actual Observation'],df['Predicted Price']))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
